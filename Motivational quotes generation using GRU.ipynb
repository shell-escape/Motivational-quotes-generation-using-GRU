{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "4_My. Генерация лозунгов с помощью RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqhE3ho6_1W-"
      },
      "source": [
        "# Motivational quotes generation using character/BPE GRU\n",
        "### Based on course [\"Нейронные сети и обработка текста\"](https://stepik.org/course/54098/)\n",
        "\n",
        "If you are going to read this notebook, I recommend you to open it in [google colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true) and start reading from [the beginning of the analysis](#scrollTo=rPtOSQEdx3sH), using the attached hyperlinks on functions and classes if you need to."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztTfY1QDDTTJ"
      },
      "source": [
        "### Some examples of character GRU model work:\r\n",
        "\r\n",
        " - \"The condition of the buildings are real wrongs of the people.\"\r\n",
        " - \"I am not a real impact on the table of God\"\r\n",
        " - \"I want to lose my life being weird. I'm not that bus up, emotion, and that's what I've been turned.\"\r\n",
        " - \"The real liberation of it is the result of right.\"\r\n",
        " - \"I think the best way to do is to love it all the time.\"\r\n",
        " - \"I don't really care about the truth.\"\r\n",
        " - \"I am not an award-centrance. I'm big and I'm very lucky.\"\r\n",
        "\r\n",
        "with start phrase \"Neural networks\":\r\n",
        " - \"Neural networks are decisivenial, no nature, and we need to struggle detective news we are passionate.\"\r\n",
        " - \"Neural networks are only bread neuronds of their connection; they can only give a character than to go to their projects.\"\r\n",
        " - \"Neural networks is a compliment to a new enemy.\"\r\n",
        " - \"Neural networks have a very common struggle for me.\"\r\n",
        " - \"Neural networks can be a gentleman in the universe.\"\r\n",
        " - \"Neural networks from the present of the earth is the best construction of the pressure of being able to continue to destroy the results of the world.\"\r\n",
        " - \"Neural networks and their opinion is the best thing I love.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Yb5wg9v0gc"
      },
      "source": [
        "## Required libraries, functions and classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOApOY1xFV1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c80ae7c-bacc-4ebf-c623-e1ef6712355e"
      },
      "source": [
        "!pip3 install livelossplot --quiet\r\n",
        "!pip3 install youtokentome --quiet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▏                               | 10kB 28.7MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 36.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 26.0MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 22.7MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 24.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61kB 17.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71kB 17.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81kB 18.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92kB 16.1MB/s eta 0:00:01\r\u001b[K     |██                              | 102kB 17.4MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 17.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 122kB 17.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 133kB 17.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143kB 17.4MB/s eta 0:00:01\r\u001b[K     |██▉                             | 153kB 17.4MB/s eta 0:00:01\r\u001b[K     |███                             | 163kB 17.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 174kB 17.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 184kB 17.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 194kB 17.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 204kB 17.4MB/s eta 0:00:01\r\u001b[K     |████                            | 215kB 17.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 225kB 17.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 235kB 17.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 245kB 17.4MB/s eta 0:00:01\r\u001b[K     |████▉                           | 256kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 266kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 276kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 286kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 296kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 307kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 317kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 327kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 337kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 348kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 358kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 368kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 378kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 389kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 399kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 409kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 419kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 430kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 440kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 450kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 460kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 471kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 481kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 491kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 501kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 512kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 522kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 532kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 542kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 552kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 563kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 573kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 583kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 593kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 604kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 614kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 624kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 634kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 645kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 655kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 665kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 675kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 686kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 696kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 706kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 716kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 727kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 737kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 747kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 757kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 768kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 778kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 788kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 798kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 808kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 819kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 829kB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 839kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 849kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 860kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 870kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 880kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 890kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 901kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 911kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 921kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 931kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 942kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 952kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 962kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 972kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 983kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 993kB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.0MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.0MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.0MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.0MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.1MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.1MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.1MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.1MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.2MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.2MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.2MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.2MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.2MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.3MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.3MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.3MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.3MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.3MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.4MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.4MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.4MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.4MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.4MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.4MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.4MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.5MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.5MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.5MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.5MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.5MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.5MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.5MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.5MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.6MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6MB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.6MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.6MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.6MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.6MB 17.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.6MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.7MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.7MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.7MB 17.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.7MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7MB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7MB 17.4MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:20:34.854793Z",
          "start_time": "2019-11-05T18:20:34.372865Z"
        },
        "id": "vxLHOfuc_1W_"
      },
      "source": [
        "from google.colab import drive, files\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import youtokentome as yttm\n",
        "\n",
        "import random\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import datetime\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "\n",
        "from traceback import format_exc\n",
        "\n",
        "from copy import deepcopy"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JluedzS-KBVa"
      },
      "source": [
        "def init_random_seed(value=0):\n",
        "    random.seed(value)\n",
        "    np.random.seed(value)\n",
        "    torch.manual_seed(value)\n",
        "    torch.cuda.manual_seed(value)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "init_random_seed()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA9oE_KOKxwq"
      },
      "source": [
        "def copy_data_to_device(data, device):\n",
        "    if torch.is_tensor(data):\n",
        "        return data.to(device)\n",
        "    elif isinstance(data, (list, tuple)):\n",
        "        return [copy_data_to_device(elem, device) for elem in data]\n",
        "    raise ValueError('Invalid data type {}'.format(type(data)))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL7pt4XK2RPh"
      },
      "source": [
        "def divisors(n):\n",
        "    \"\"\"Find all divisors of a number\"\"\"\n",
        "    i = 1\n",
        "    divisors = []\n",
        "    while i <= n**0.5:\n",
        "        if (n % i == 0) : \n",
        "            if (n / i == i):\n",
        "                divisors.append(i)\n",
        "            else:\n",
        "                divisors.extend([i, n // i])\n",
        "        i = i + 1\n",
        "    return sorted(divisors)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giIjs1JOvvvE"
      },
      "source": [
        "def to_matrix(data, token_to_id=None, max_len=None, dtype='int32', batch_first=True):\n",
        "    \"\"\"Casts a list of names into rnn-digestable matrix\n",
        "       parameter token_to_id is None mean that the data is already tokenized\"\"\"\n",
        "    \n",
        "    if token_to_id is None:\n",
        "        data_ix = np.zeros([len(data), max_len], dtype)\n",
        "        for i in range(len(data)):\n",
        "            line_ix = data[i]\n",
        "            data_ix[i, :len(line_ix)] = line_ix\n",
        "    else:\n",
        "        data_ix = np.zeros([len(data), max_len], dtype) + token_to_id[' ']\n",
        "        for i in range(len(data)):\n",
        "            line_ix = [token_to_id[c] for c in data[i]]\n",
        "            data_ix[i, :len(line_ix)] = line_ix\n",
        "        \n",
        "    if not batch_first: # convert [batch, time] into [time, batch]\n",
        "        data_ix = np.transpose(data_ix)\n",
        "\n",
        "    return data_ix\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QZ4jvNtRoop"
      },
      "source": [
        "class RNN_model(nn.Module):\n",
        "    def __init__(self, model_type, num_tokens, emb_size=16, hidden_size=64, num_layers=1):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
        "        if model_type == \"VanillaRNN\":\n",
        "            self.rnn = nn.RNN(emb_size, hidden_size, num_layers, batch_first=True)\n",
        "        elif model_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(emb_size, hidden_size, num_layers, batch_first=True)\n",
        "        elif model_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(emb_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.hid_to_logits = nn.Linear(hidden_size, num_tokens)\n",
        "\n",
        "    def forward(self, x, hidden=None):  # may pass hidden when generating\n",
        "        if hidden is None:\n",
        "            rnn_out, hidden = self.rnn(self.emb(x))\n",
        "        else:\n",
        "            rnn_out, hidden = self.rnn(self.emb(x), hidden)\n",
        "        logits = self.hid_to_logits(rnn_out)\n",
        "        logits = F.log_softmax(logits, dim=-1)\n",
        "        return logits, hidden\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-aBS-yD5Crc"
      },
      "source": [
        "def train_eval_loop(model, dataset, vocab=None, lr=1e-3, epoch_n=10, batch_size=32,\n",
        "                    device=None, early_stopping_patience=10, l2_reg_alpha=0, \n",
        "                    optimizer_ctor=None, lr_scheduler_ctor=None, \n",
        "                    draw_loss=False, show_bar=False, show_lr=False):\n",
        "\n",
        "    if device is None:\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    device = torch.device(device)\n",
        "    model.to(device)\n",
        "\n",
        "    if optimizer_ctor is None:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\n",
        "    else:\n",
        "        optimizer = optimizer_ctor(model.parameters(), lr=lr)\n",
        "    \n",
        "    if lr_scheduler_ctor is not None:\n",
        "        lr_scheduler = lr_scheduler_ctor(optimizer)\n",
        "    else:\n",
        "        lr_scheduler = None\n",
        "    \n",
        "    if draw_loss:\n",
        "        liveplot = PlotLosses()\n",
        "\n",
        "    best_loss = float(\"inf\")\n",
        "    best_epoch_i = 0\n",
        "    best_model = deepcopy(model)\n",
        "\n",
        "    MAX_LEN = max(map(len, dataset))\n",
        "    \n",
        "    loss_functor = nn.NLLLoss()\n",
        "\n",
        "    for epoch_i in range(epoch_n):\n",
        "        try:\n",
        "            if not draw_loss:\n",
        "                epoch_start = datetime.datetime.now()\n",
        "                print(f\"Epoch {epoch_i}\")\n",
        "\n",
        "            model.train()\n",
        "            mean_loss = 0\n",
        "            batches_n = len(quotes) // batch_size\n",
        "\n",
        "            for i in tqdm(range(batches_n)) if show_bar else range(batches_n):\n",
        "                batch_ix = to_matrix(random.sample(dataset, batch_size), vocab, max_len=MAX_LEN)\n",
        "                batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
        "                batch_ix = copy_data_to_device(batch_ix, device)\n",
        "    \n",
        "                logp_seq, _ = model(batch_ix)\n",
        "                \n",
        "                predictions_logp = logp_seq[:, :-1].reshape(batch_size * (MAX_LEN - 1), -1)\n",
        "\n",
        "                actual_next_tokens = batch_ix[:, 1:].reshape(batch_size * (MAX_LEN - 1))\n",
        "\n",
        "                loss = loss_functor(predictions_logp, actual_next_tokens)\n",
        "\n",
        "                model.zero_grad()\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                mean_loss += float(loss)\n",
        "\n",
        "            mean_loss /= batches_n\n",
        "\n",
        "            if not draw_loss:\n",
        "                print('{} iterations for training and {} for validation, {:0.2f} sec'.format(train_batches_n, val_batches_n,\n",
        "                                                           (datetime.datetime.now() - epoch_start).total_seconds()))\n",
        "                print('Average value of the train loss function:', mean_train_loss)\n",
        "                print('Average value of the validation loss function:', mean_val_loss)\n",
        "            else:\n",
        "                liveplot.update({'mean loss': mean_loss})\n",
        "                liveplot.draw()\n",
        "            \n",
        "            if mean_loss < best_loss:\n",
        "                best_epoch_i = epoch_i\n",
        "                best_loss = mean_loss\n",
        "                best_model = deepcopy(model)\n",
        "                if not draw_loss:\n",
        "                    print('New best model!')\n",
        "            elif epoch_i - best_epoch_i > early_stopping_patience:\n",
        "                print(f\"The model has not improved over the last {early_stopping_patience} epochs, stop training\")\n",
        "                break\n",
        "\n",
        "            if lr_scheduler is not None:\n",
        "                if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                    lr_scheduler.step(mean_loss)\n",
        "                elif isinstance(lr_scheduler, torch.optim.lr_scheduler.StepLR):\n",
        "                    lr_scheduler.step()\n",
        "                    if show_lr:\n",
        "                        print(optimizer.param_groups[0]['lr'])\n",
        "                else:\n",
        "                    lr_scheduler.step()\n",
        "\n",
        "            print()\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print('Stopped early by user')\n",
        "            break\n",
        "        except Exception as ex:\n",
        "            print('Error while training: {}\\n{}'.format(ex, format_exc()))\n",
        "            break\n",
        "\n",
        "    return best_loss, best_model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN2bUYhoZJX2"
      },
      "source": [
        "def generate_sample(model, tokens, token_to_id, max_length, seed_phrase=' ', temperature=1.0, device=None):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "                        smaller temperature converges to the single most likely output\n",
        "    '''\n",
        "    \n",
        "    if device is None:\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    device = torch.device(device)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        x_sequence = [[token_to_id[token] for token in seed_phrase]]\n",
        "        x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
        "        x_sequence = copy_data_to_device(x_sequence, device)\n",
        "        \n",
        "        hidden = None\n",
        "\n",
        "        if len(seed_phrase) > 1:\n",
        "            _, hidden = model(torch.squeeze(x_sequence[:, :, :-1], 0))\n",
        "\n",
        "        for _ in range(max_length - len(seed_phrase)):\n",
        "            logp_next, hidden = model(x_sequence[:, :, -1], hidden)\n",
        "            p_next = F.softmax(logp_next / temperature, dim=-1).data.cpu().numpy()[0]\n",
        "            next_ix = np.random.choice(len(tokens), p=p_next[0])\n",
        "            next_ix = torch.tensor([[[next_ix]]], dtype=torch.int64)\n",
        "            x_sequence = copy_data_to_device(torch.cat([x_sequence.cpu(), next_ix], dim=2), device)\n",
        "\n",
        "        return ''.join([tokens[ix] for ix in x_sequence[0, 0].data.cpu().numpy()])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV8Bhw02i4sc"
      },
      "source": [
        "def generate_sample_bpe(model, tokenizer, max_length, seed_phrase=' ', temperature=1.0, device=None):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "                        smaller temperature converges to the single most likely output\n",
        "    '''\n",
        "    \n",
        "    if device is None:\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    device = torch.device(device)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "        x_sequence = [tokenizer.encode(seed_phrase, bos=True, eos=False)]\n",
        "        x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
        "        x_sequence = copy_data_to_device(x_sequence, device)\n",
        "        \n",
        "        hidden = None\n",
        "\n",
        "        if len(seed_phrase) > 1:\n",
        "            _, hidden = model(torch.squeeze(x_sequence[:, :, :-1], 0))\n",
        "\n",
        "        length = len(seed_phrase) - 1 # subtrack one because encoding ignore whitespace at the begining\n",
        "        while True:\n",
        "            logp_next, hidden = model(x_sequence[:, :, -1], hidden)\n",
        "            p_next = F.softmax(logp_next / temperature, dim=-1).data.cpu().numpy()[0]\n",
        "            next_ix = np.random.choice(len(tokenizer.vocab()), p=p_next[0])\n",
        "            if next_ix not in [2, 3]:\n",
        "                length += len(tokenizer.vocab()[next_ix])\n",
        "            if length > max_length:\n",
        "                 break\n",
        "            next_ix = torch.tensor([[[next_ix]]], dtype=torch.int64)\n",
        "            x_sequence = copy_data_to_device(torch.cat([x_sequence.cpu(), next_ix], dim=2), device)\n",
        "\n",
        "        return ''.join(tokenizer.decode(x_sequence[0, 0].data.cpu().numpy().tolist(), ignore_ids=[0,2,3])) #ignore <PAD>, <BOS>, <EOS>\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPtOSQEdx3sH"
      },
      "source": [
        "## Loading data & preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfPqRIBUwQ9k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5658d3-87a7-4d37-9e36-598c6a673f9a"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:21:03.509714Z",
          "start_time": "2019-11-05T18:21:03.491489Z"
        },
        "id": "x9P7lHl7_1W_"
      },
      "source": [
        "dataset_filename = \"/content/gdrive/My Drive/ML/datasets/author_quotes.txt\"\n",
        "with open(dataset_filename) as input_file:\n",
        "    quotes = input_file.read().split('\\n')\n",
        "    quotes = [' ' + line for line in quotes]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:21:03.946758Z",
          "start_time": "2019-11-05T18:21:03.938432Z"
        },
        "id": "7Q_dIWmJ_1W_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1fc4801-fd19-430a-c525-a134d7fa11d9"
      },
      "source": [
        "quotes_n = len(quotes)\n",
        "print(f\"Number of quotes: {quotes_n}\")\n",
        "quotes[:5]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of quotes: 36166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' If you live to be a hundred, I want to live to be a hundred minus one day so I never have to live without you.',\n",
              " \" Promise me you'll always remember: You're braver than you believe, and stronger than you seem, and smarter than you think.\",\n",
              " ' Did you ever stop to think, and forget to start again?',\n",
              " ' Organizing is what you do before you do something, so that when you do it, it is not all mixed up.',\n",
              " ' Weeds are flowers too, once you get to know them.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owishpHL_1W_"
      },
      "source": [
        "### Quote length distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:21:05.420060Z",
          "start_time": "2019-11-05T18:21:05.179513Z"
        },
        "id": "kG1b0g28_1W_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "fb7ac121-dc92-4363-c58d-a20843a768c0"
      },
      "source": [
        "plt.title('Quote length distribution')\n",
        "plt.hist(list(map(len, quotes)), bins=25);"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em5_JSKm_1W_"
      },
      "source": [
        "### Creating a dictionary {symbol: id}:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2J_3Inm0UmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f00bff2-e0bc-42a5-f301-cce42e8dc42c"
      },
      "source": [
        "tokens = list(set(''.join(quotes)))\n",
        "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
        "num_tokens = len(tokens)\n",
        "\n",
        "print(f\"Number of unique tokens: {num_tokens}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique tokens: 85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iPC6dIF3I_t"
      },
      "source": [
        "### Finding the appropriate batch size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0EcfUqf3ICj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18bf3a6c-05ac-49aa-c010-02c7fb51bb24"
      },
      "source": [
        "print(f\"divisors of number of quotes ({quotes_n}) are {divisors(quotes_n)}\")\n",
        "batch_size = 214"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "divisors of number of quotes (36166) are [1, 2, 13, 26, 107, 169, 214, 338, 1391, 2782, 18083, 36166]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rvxT91A49Yh"
      },
      "source": [
        "## Byte pair encoding (BPE) tokenization instead of characters using [youtokentome library](https://pypi.org/project/youtokentome/) :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY_9EDBFFVqf"
      },
      "source": [
        "num_tokens_bpe = 300\n",
        "bpe_model_filename = \"/tmp/quotes_bpe.yttm\"\n",
        "yttm.BPE.train(data=dataset_filename, vocab_size=num_tokens_bpe, model=bpe_model_filename)\n",
        "tokenizer = yttm.BPE(bpe_model_filename)\n",
        "quotes_bpe = tokenizer.encode(quotes, bos=True, eos=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvYTX51M5v4u"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTxDBv462CaG"
      },
      "source": [
        "## [Character GRU model](#scrollTo=2QZ4jvNtRoop&line=1&uniqifier=1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTYYUdas2LMv"
      },
      "source": [
        "EMB_SIZE = 128\r\n",
        "HIDDEN_SIZE = 256\r\n",
        "NUM_LAYERS = 3\r\n",
        "\r\n",
        "char_gru_model = RNN_model(\"GRU\", num_tokens, emb_size=EMB_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yh5woVw2W4r"
      },
      "source": [
        "### [Training](#scrollTo=0-aBS-yD5Crc&line=1&uniqifier=1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dciemxB2WPV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "outputId": "fe3d9c90-3ae1-41e6-8c00-7a505adb2d73"
      },
      "source": [
        "# scheduler = lambda optim: \\\n",
        "#     torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=5, factor=0.5, verbose=True)\n",
        "\n",
        "scheduler = lambda optim: \\\n",
        "    torch.optim.lr_scheduler.StepLR(optim, step_size=10, gamma=0.95)\n",
        "\n",
        "best_char_gru_loss, best_char_gru_model = train_eval_loop(model=char_gru_model,\n",
        "                                                          dataset=quotes,\n",
        "                                                          vocab=token_to_id,\n",
        "                                                          lr=1e-3,\n",
        "                                                          epoch_n=100,\n",
        "                                                          batch_size=batch_size, \n",
        "                                                          early_stopping_patience=10,\n",
        "                                                          l2_reg_alpha=0,\n",
        "                                                          lr_scheduler_ctor=scheduler,\n",
        "                                                          draw_loss=True)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbkAAAI4CAYAAAD3UJfIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5zdVX3v/9dn7z2XzGRyn9wTkmBICISbIaCIRMCCVKWtl0KpijdOj9JqW+3RntZazs+2p+1DWyvHVlu8YCtVvEVF0XITUSChXARCIOQ6ISST+3Xu6/fH3jNMJjPJkEyyM9/9ej4e88js7/7Od6/Zj528s9ZnfdeKlBKSJGVRrtwNkCTpeDHkJEmZZchJkjLLkJMkZZYhJ0nKLENOkpRZhpw0zEXEvRHxvnK3QzoZGXKSpMwy5CRJmWXISYMUEWsj4qMR8URE7IuIf4uISRHxo4jYExH/FRFje51/YUT8IiJ2RsTjEbGk13PvjogVpZ9bHRH/o9dzSyKiKSL+OCK2RMSmiHj3INuYi4g/i4h1pZ/9akSMLj1XGxFfi4htpTYti4hJpeeuL7VjT0SsiYjrhuyNk8rIkJNenrcArwdOA94E/Aj4U6CR4t+nPwCIiGnAD4H/DxgHfAT4VkQ0lq6zBXgjMAp4N/CZiDiv1+tMBkYD04D3Ajf3DtDDuL709TpgDjAS+FzpuXeVrjkDGA/8HnAgIuqBzwJvSCk1AK8GHhvk+yGd1Aw56eX5p5TS5pTSRuB+4KGU0qMppRbgO8C5pfN+F7gjpXRHSqkrpfRTYDlwFUBK6YcppedT0X3AT4CLe71OO3BTSqk9pXQHsBeYN4j2XQd8OqW0OqW0F/g4cE1EFErXHA+8IqXUmVJ6JKW0u/RzXcCZETEipbQppfTUUb9D0knEkJNens29vj/Qz+ORpe9PAd5WGhbcGRE7gdcAUwAi4g0R8WBEbC89dxUwode1tqWUOno93t/r2oczFVjX6/E6oABMAm4F7gRui4gXIuJvI6IqpbQP+G2KPbtNEfHDiJg/iNeSTnqGnHR8bABuTSmN6fVVn1L6m4ioAb4F/D0wKaU0BrgDiCF43RcoBmy3mUAHsLnUK/zLlNICikOSbwTeCZBSujOl9HqKIfwM8MUhaItUdoacdHx8DXhTRFwREfnSpI8lETEdqAZqgGagIyLeAPzaEL3u14E/jIjZETES+CvgP1NKHRHxuohYGBF5YDfF4cuu0uSZq0u1uVaKQ6NdQ9QeqawMOek4SCltAK6mOCmlmWLP7qNALqW0h+IElW8AO4DfAZYO0UvfQnFY8mfAGqAF+P3Sc5OB2ykG3ArgvtK5OeCPKPYCtwOXAP9ziNojlVW4aaokKavsyUmSMsuQkyRlliEnScosQ06SlFmFcr3whAkT0qxZs8r18pKkjHjkkUe2ppQa+3uubCE3a9Ysli9fXq6XlyRlRESsG+g5hyslSZllyEmSMsuQkyRlliEnScosQ06SlFmGnCQpsww5SVJmGXKSpMwy5CRJmWXISZIyy5CTJGWWISdJyixDTpKUWYacJCmzDDlJUmYZcpKkzDLkJEmZZchJkjLLkJMkZZYhJ0nKrGEdclv3tnLPM1vY3dJe7qZIkk5CRwy5iLglIrZExJMDPB8R8dmIWBURT0TEeUPfzP49vmEn7/7yMtZu3XeiXlKSNIwMpif3ZeDKwzz/BmBu6esG4PPH3qzByecCgI6udKJeUpI0jBwx5FJKPwO2H+aUq4GvpqIHgTERMWWoGng4hVyx+Z2GnCSpH0NRk5sGbOj1uKl07BARcUNELI+I5c3Nzcf8wt09ufbOrmO+liQpe07oxJOU0hdSSotSSosaGxuP+XpV+WLI2ZOTJPVnKEJuIzCj1+PppWPHnTU5SdLhDEXILQXeWZpleSGwK6W0aQiue0Q9NblOQ06SdKjCkU6IiK8DS4AJEdEE/AVQBZBS+mfgDuAqYBWwH3j38WpsXy/15KzJSZIOdcSQSylde4TnE/DBIWvRy1DIO1wpSRrYsF7xpJBz4okkaWDDPOSKze+wJidJ6sewDrm8txBIkg5jWIdc93BluxNPJEn9yETI2ZOTJPVnmIecNTlJ0sCGdchZk5MkHc6wDjlrcpKkwxnWIde94onLekmS+jOsQ67gAs2SpMMY1iEXEeRzYU1OktSvYR1yUByytCcnSerPsA+5Qi7ocGdwSVI/shFy9uQkSf0Y/iGXz1mTkyT1a9iHnDU5SdJAhn3IWZOTJA1k2IectxBIkgYy7EOuKp9zuFKS1K9hH3L25CRJAxn2IVe8hcCanCTpUMM+5PK5cD85SVK/hn3IFazJSZIGMPxDzpqcJGkAwz7k8tbkJEkDGPYhV7AmJ0kawLAPOZf1kiQNZNiHXJULNEuSBjDsQ86enCRpIMM+5IqzK514Ikk61LAPOW8GlyQNZNiHnAs0S5IGMuxDzgWaJUkDGfYh5wLNkqSBDPuQsyYnSRrIsA+5grcQSJIGMPxDzpvBJUkDGP4hZ01OkjSAYR9yzq6UJA1k2IdcIRe0dyZSMugkSQcb/iGXL/4KduYkSX0N+5DL5wLAupwk6RDDPuQKpZCzLidJ6mvYh1x3T67dG8IlSX0M+5CzJydJGsjwD7nSxBNrcpKkvoZ/yNmTkyQNYNiHXM/sSmtykqQ+hn3IFfLdtxAYcpKkgw3/kMsVf4VOa3KSpD4yEHL25CRJ/Rv2IWdNTpI0kGEfctbkJEkDGfYhl7cmJ0kawLAPuSqHKyVJAxhUyEXElRGxMiJWRcTH+nn+lIi4KyKeiIh7I2L60De1f3lvBpckDeCIIRcReeBm4A3AAuDaiFjQ57S/B76aUjoLuAn466Fu6ECsyUmSBjKYntxiYFVKaXVKqQ24Dbi6zzkLgLtL39/Tz/PHTXdNzrUrJUl9DSbkpgEbej1uKh3r7XHgt0rf/ybQEBHjj715R1awJidJGsBQTTz5CHBJRDwKXAJsBDr7nhQRN0TE8ohY3tzcPCQv3D1caU1OktTXYEJuIzCj1+PppWM9UkovpJR+K6V0LvC/S8d29r1QSukLKaVFKaVFjY2Nx9Dsl7jiiSRpIIMJuWXA3IiYHRHVwDXA0t4nRMSEiOi+1seBW4a2mQOzJidJGsgRQy6l1AHcCNwJrAC+kVJ6KiJuiog3l05bAqyMiGeBScCnjlN7D2FNTpI0kMJgTkop3QHc0efYJ3p9fztw+9A2bXCsyUmSBjLsVzzJW5OTJA1g2IfcS/vJGXKSpIMN+5Dr7sm1dzrxRJJ0sGEfclXW5CRJAxj2IWdNTpI0kGEfctbkJEkDGfYhV+rI0WFNTpLUx7APuYigkAuHKyVJhxj2IQfFG8IdrpQk9ZWNkMvl7MlJkg6RiZDL5+zJSZIOlYmQK+TCm8ElSYfIRshZk5Mk9SMbIWdNTpLUj0yEnDU5SVJ/MhFy1uQkSf3JRMjZk5Mk9ScTIVfIW5OTJB0qGyFnT06S1I9MhFzetSslSf3IRMgVcuEuBJKkQ2Qj5PL25CRJh8pGyOVy1uQkSYfIRMhZk5Mk9ScTIWdNTpLUn0yEnDeDS5L6k4mQq/JmcElSPzIRcvbkJEn9yUTIFXJBR5c1OUnSwTIRcvlc0NFpT06SdLBMhJwLNEuS+pONkLMmJ0nqRyZCLu99cpKkfmQi5AqueCJJ6kcmQi7vAs2SpH5kIuSqXKBZktSPTIRc983gKRl0kqSXZCLkCrkAsDcnSTpIJkIuny+GnHU5SVJvmQi5qlzx1zDkJEm9ZSLk8t3DlS7tJUnqJRMhV+gZrvSGcEnSSzIRct09OYcrJUm9ZSLkCoacJKkfGQm54q9hTU6S1Fs2Qs6anCSpH5kIubw3g0uS+pGJkOuuybU7XClJ6iUjIVeqydmTkyT1komQy1uTkyT1IxMh5wLNkqT+ZCLk8tbkJEn9yETIWZOTJPUnGyFnTU6S1I9shJw1OUlSPzIRci7QLEnqz6BCLiKujIiVEbEqIj7Wz/MzI+KeiHg0Ip6IiKuGvqkD667JdTjxRJLUyxFDLiLywM3AG4AFwLURsaDPaX8GfCOldC5wDfD/hrqhh2NNTpLUn8H05BYDq1JKq1NKbcBtwNV9zknAqNL3o4EXhq6JR2ZNTpLUn8GE3DRgQ6/HTaVjvX0S+N2IaALuAH6/vwtFxA0RsTwiljc3Nx9Fc/tnTU6S1J+hmnhyLfDllNJ04Crg1og45NoppS+klBallBY1NjYO0Utbk5Mk9W8wIbcRmNHr8fTSsd7eC3wDIKX0S6AWmDAUDRyMl7basSYnSXrJYEJuGTA3ImZHRDXFiSVL+5yzHrgMICJOpxhyQzceeQRVeYcrJUmHOmLIpZQ6gBuBO4EVFGdRPhURN0XEm0un/THw/oh4HPg6cH1K6YQljpumSpL6UxjMSSmlOyhOKOl97BO9vn8auGhomzZ4PTU5Q06S1Eu2VjzptCYnSXpJJkKu4C0EkqR+ZCLkcrkgF9bkJEkHy0TIQbEuZ09OktRbZkIunwtrcpKkg2Qm5Aq5sCcnSTpIdkIuH9bkJEkHyUzI5a3JSZL6yEzIFXJBpws0S5J6yUzI5XNBuws0S5J6yUzIVVmTkyT1kZmQyzu7UpLUR2ZCrpDLWZOTJB0kMyFX7MlZk5MkvSQzIVfIO1wpSTpYdkIu58QTSdLBMhRyOTqsyUmSeslMyOXtyUmS+shMyBXy3gwuSTpYdkLOnpwkqY/MhFzempwkqY/MhJw9OUlSX5kJubw1OUlSH5kJOXtykqS+MhRy1uQkSQfLUMjZk5MkHSwzIZd37UpJUh+ZCbmCuxBIkvrIUMi5n5wk6WDZCTmHKyVJfWQm5FygWZLUV2ZCrpDzZnBJ0sEyE3L5XJASdNmbkySVZCbkqvLFX8W6nCSpW2ZCLp8LAOtykqQemQm5QinkvFdOktQtMyHX3ZNz/UpJUrfMhFzBmpwkqY/shJw1OUlSH5kJubw1OUlSH5kJuYI1OUlSH5kJuZd6coacJKkoMyHXfTO4NTlJUrfMhJw1OUlSX5kJOWdXSpL6ykzIdffk2p14IkkqyUzIWZOTJPWVmZCzJidJ6iszIWdNTpLUV2ZCzgWaJUl9ZSbkCjkXaJYkHSw7IZfvHq60JidJKspOyLmslySpj8yEXN6JJ5KkPjITct01OW8GlyR1G1TIRcSVEbEyIlZFxMf6ef4zEfFY6evZiNg59E09PGtykqS+Ckc6ISLywM3A64EmYFlELE0pPd19TkrpD3ud//vAucehrYdlTU6S1NdgenKLgVUppdUppTbgNuDqw5x/LfD1oWjcy2FNTpLU12BCbhqwodfjptKxQ0TEKcBs4O4Bnr8hIpZHxPLm5uaX29bDsiYnSeprqCeeXAPcnlLq7O/JlNIXUkqLUkqLGhsbh/SF89bkJEl9DCbkNgIzej2eXjrWn2sow1AlWJOTJB1qMCG3DJgbEbMjoppikC3te1JEzAfGAr8c2iYOTs8CzQ5XSpJKjhhyKaUO4EbgTmAF8I2U0lMRcVNEvLnXqdcAt6WUypIyPZum2pOTJJUc8RYCgJTSHcAdfY59os/jTw5ds16+iCCfC2tykqQemVnxBIpDltbkJEndMhdy1uQkSd0yFXJ5e3KSpF4yFXKFfI4Oa3KSpJJMhVxx4ok9OUlSUaZCrioXdFiTkySVZCrk8nl7cpKkl2Qq5Aq5nDeDS5J6ZCrkvBlcktRbpkKuYE1OktRLtkLOmpwkqZdMhVw+l/NmcElSj0yFXHHtSmtykqSiTIVc3pqcJKmXTIVclTU5SVIvmQo5a3KSpN4yFXLW5CRJvWUq5KzJSZJ6y1TIWZOTJPWWqZDL53KGnCSpR6HcDRhKBXcGl3SSaG9vp6mpiZaWlnI3JTNqa2uZPn06VVVVg/6ZTIVcsSbnxBNJ5dfU1ERDQwOzZs0iIsrdnGEvpcS2bdtoampi9uzZg/65TA1X2pOTdLJoaWlh/PjxBtwQiQjGjx//snvG2Qq5vCEn6eRhwA2to3k/MxVyI6ryHGjrLHczJEkniUyFXF11gQPtnc6wlKQyu/7667n99tvL3YxshVx9TR6AA+325iRJGQu5uuriZNH9rR1lbokkldfatWuZP38+119/PaeddhrXXXcd//Vf/8VFF13E3LlzefjhhwHYt28f73nPe1i8eDHnnnsu3/ve93p+/uKLL+a8887jvPPO4xe/+AUA9957L0uWLOGtb30r8+fP57rrriOlw4+e3XXXXZx77rksXLiQ97znPbS2tgLwsY99jAULFnDWWWfxkY98BIBvfvObnHnmmZx99tm89rWvPeb3IVO3EHT35PZbl5N0EvnL7z/F0y/sHtJrLpg6ir940xmHPWfVqlV885vf5JZbbuH888/nP/7jP/j5z3/O0qVL+au/+iu++93v8qlPfYpLL72UW265hZ07d7J48WIuv/xyJk6cyE9/+lNqa2t57rnnuPbaa1m+fDkAjz76KE899RRTp07loosu4oEHHuA1r3lNv21oaWnh+uuv56677uK0007jne98J5///Od5xzvewXe+8x2eeeYZIoKdO3cCcNNNN3HnnXcybdq0nmPHIpM9uX1t9uQkafbs2SxcuJBcLscZZ5zBZZddRkSwcOFC1q5dC8BPfvIT/uZv/oZzzjmHJUuW0NLSwvr162lvb+f9738/Cxcu5G1vextPP/10z3UXL17M9OnTyeVynHPOOT3X6s/KlSuZPXs2p512GgDvete7+NnPfsbo0aOpra3lve99L9/+9repq6sD4KKLLuL666/ni1/8Ip2dx95hyVZPrnu40p6cpJPIkXpcx0tNTU3P97lcrudxLpejo6PYGUgp8a1vfYt58+Yd9LOf/OQnmTRpEo8//jhdXV3U1tb2e918Pt9zrZejUCjw8MMPc9ddd3H77bfzuc99jrvvvpt//ud/5qGHHuKHP/whr3zlK3nkkUcYP378y75+t2z15ErDlfusyUnSoFxxxRX80z/9U09d7dFHHwVg165dTJkyhVwux6233nrUvap58+axdu1aVq1aBcCtt97KJZdcwt69e9m1axdXXXUVn/nMZ3j88ccBeP7557ngggu46aabaGxsZMOGDcf0+2WqJ1dXbU1Okl6OP//zP+fDH/4wZ511Fl1dXcyePZsf/OAHfOADH+Atb3kLX/3qV7nyyiupr68/quvX1tbypS99ibe97W10dHRw/vnn83u/93ts376dq6++mpaWFlJKfPrTnwbgox/9KM899xwpJS677DLOPvvsY/r94kizYo6XRYsWpe4i5lDZsH0/F//tPfzdW8/ibYtmDOm1JenlWLFiBaeffnq5m5E5/b2vEfFISmlRf+dna7jSnpwkqZdMhVx9jbMrJUkvyVTI1RRy5AL2t9qTk1R+5SoHZdXRvJ+ZCrmIoL66YE9OUtnV1taybds2g26IdO8n1/tWhsHI1OxKKN5G4E4Ekspt+vTpNDU10dzcXO6mZEb3zuAvR+ZCrtiTM+QklVdVVdXL2sFax0emhiuh2JNzgWZJEmQx5KzJSZJKMhhyee+TkyQBGQy5+uqCa1dKkoAMhpw9OUlSt8yFXH2NPTlJUlHmQs6enCSpW+ZCrr6mQEdXoq2jq9xNkSSVWeZC7qWdCByylKRKl7mQq6/u3onAIUtJqnSZC7m6mlJPzsknklTxMhdy9uQkSd0yF3Ijqu3JSZKKMhdy9uQkSd0yF3I9NTlnV0pSxRtUyEXElRGxMiJWRcTHBjjn7RHxdEQ8FRH/MbTNHLyenlyrPTlJqnRH3DQ1IvLAzcDrgSZgWUQsTSk93eucucDHgYtSSjsiYuLxavCR2JOTJHUbTE9uMbAqpbQ6pdQG3AZc3eec9wM3p5R2AKSUtgxtMwevrqo75OzJSVKlG0zITQM29HrcVDrW22nAaRHxQEQ8GBFX9nehiLghIpZHxPLm5uaja/ERFPI5ago5N06VJA3ZxJMCMBdYAlwLfDEixvQ9KaX0hZTSopTSosbGxiF66UPV1xTYb01OkireYEJuIzCj1+PppWO9NQFLU0rtKaU1wLMUQ68s6qrz9uQkSYMKuWXA3IiYHRHVwDXA0j7nfJdiL46ImEBx+HL1ELbzZamrztuTkyQdOeRSSh3AjcCdwArgGymlpyLipoh4c+m0O4FtEfE0cA/w0ZTStuPV6COpqy7Yk5MkHfkWAoCU0h3AHX2OfaLX9wn4o9JX2dXXuHGqJCmDK55AqSfn2pWSVPEyGXL11fbkJEkZDbm6moIhJ0nKZsgVe3IOV0pSpctkyNVVF3tyXV2p3E2RJJVRJkOuvrRI84F2hywlqZJlMuTqejZOdchSkipZRkOutBOBq55IUkXLaMjZk5MkZTTk6mvcU06SlNGQ6+nJueqJJFW0TIacPTlJEmQ15Eo9OUNOkipbJkOuZ3alE08kqaJlMuTqa7prcvbkJKmSZTLkago5cmFPTpIqXSZDLiKory7Yk5OkCpfJkAMY4U4EklTxMhty9TUF9jm7UpIqWmZDrq46z35vBpekipbZkKuvLrh2pSRVuMyGXF1NngMOV0pSRctsyBV7coacJFWyzIacNTlJUmZDztmVkqTMhlyd98lJUsXLbMjV1xRo70y0dXSVuymSpDLJbMiNqHInAkmqdJkNue6NU63LSVLlymzI1XVvnOoMS0mqWJkNOXtykqTMhlxPT86anCRVrMyGXH3PcKU9OUmqVJkNubqe4Up7cpJUqTIbcj09OWtyklSxMhtyPT05Z1dKUsXKbsj13AxuT06SKlVmQ66Qz1FdyFmTk6QKltmQA6ivzju7UpIqWLZDrqbAXmtyklSxMh1yE0bWsHVva7mbIUkqk0yH3MSGGrbsNuQkqVJlO+RG1bB5T0u5myFJKpNMh9ykhlp27m+ntcPJJ5JUiTIdchNH1QDQvMchS0mqRNkOuYZaADZbl5OkipTpkGts6O7JWZeTpEqU6ZCbNKrYk9vicKUkVaRMh9z4+mryufA2AkmqUJkOuVwumDCyms27Ha6UpEqU6ZCD4uQThyslqTJlPuQmjaox5CSpQmU+5Bobap1dKUkVKvMhN7Ghhq1722jv7Cp3UyRJJ1j2Q6606om7EUhS5cl8yE0qrXribQSSVHkGFXIRcWVErIyIVRHxsX6evz4imiPisdLX+4a+qUenuyfn5BNJqjyFI50QEXngZuD1QBOwLCKWppSe7nPqf6aUbjwObTwmL61f6eQTSao0g+nJLQZWpZRWp5TagNuAq49vs4bOhJHVRNiTk6RKNJiQmwZs6PW4qXSsr7dExBMRcXtEzOjvQhFxQ0Qsj4jlzc3NR9Hcl6+QzzG+vsbbCCSpAg3VxJPvA7NSSmcBPwW+0t9JKaUvpJQWpZQWNTY2DtFLH9nEhhonnkhSBRpMyG0EevfMppeO9UgpbUspdafIvwKvHJrmDY2Jo2rYbE9OkirOYEJuGTA3ImZHRDVwDbC09wkRMaXXwzcDK4auicduUkOtPTlJqkBHnF2ZUuqIiBuBO4E8cEtK6amIuAlYnlJaCvxBRLwZ6AC2A9cfxza/bBNH1bB1byudXYl8LsrdHEnSCXLEkANIKd0B3NHn2Cd6ff9x4OND27ShM7Ghhq4E2/a2MrG0kaokKfsyv+IJFBdpBm8jkKRKUxEhN6ln1RMnn0hSJamIkOseonTyiSRVlooIucaRxZ7cZkNOkipKRYRcdSHH2LoqhyslqcJURMgBTBpV68QTSaowFRNyjQ01hpwkVZiKCbmJDbVscbsdSaoolRNyo2po3tNKV1cqd1MkSSdIxYTcpIYaOroSO/a3lbspkqQTpGJCrudeOetyklQxKifkGrrvlbMuJ0mVomJCbsa4OgDWbN1X5pZIkk6Uigm5SaNqmdhQwxNNu8rdFEnSCVIxIQdw9owxPL5hZ7mbIUk6QSoq5M6ZMYbVW/ex60B7uZsiSToBKirkzp4+BoBfOWQpSRWhokJu4fTRADze5JClJFWCigq50SOqmNNYz2PW5SSpIlRUyEFxyPKxDTtJyeW9JCnrKjDkRtO8p5UXvSlckjKv8kJuRnHyibcSSFL2VVzInT5lFFX54HFnWEpS5lVcyNVW5Tl9yih7cpJUASou5KA4+eSJpl3uLSdJGVeRIXfW9NHsbe1g9da95W6KJOk4qsiQO6c0+eSxDdblJCnLKjLk5jSOZGRNwbqcJGVcRYZcPhcsnDaaJ1zeS5IyrSJDDor3yz29aTct7Z3lbook6Tip2JC7YPY42jsTD6/ZXu6mSJKOk4oNuQvnjKe6kOPelc3lbook6Tip2JAbUZ3nwjnjuffZLeVuiiTpOKnYkANYclojq5v3sWH7/nI3RZJ0HFR2yM1rBODeZx2ylKQsquiQmz2hnpnj6rhvpUOWkpRFFR1yEcElpzXyi+e30drhrQSSlDUVHXJQHLLc39bJsjU7yt0USdIQq/iQe9Wp46nO57jXIUtJypyKD7m66gIXzBnHfU4+kaTMqfiQA7jktEae27KXjTsPlLspkqQhZMgBS+ZNBHDIUpIyxpADTm2sZ/rYEdy1wpCTpCwx5CjeSnD1OVO5Z+UWVm1xt3BJygpDruQ9F82mppDj/927qtxNkSQNEUOuZPzIGq674BS+99gLrmUpSRlhyPVyw2vnkI/g8/c9X+6mSJKGgCHXy6RRtbxt0XRuX97Epl3eTiBJw50h18fvXXIqnSnxhZ+tLndTJEnHyJDrY8a4On7z3Gl8/eH1bN3bWu7mSJKOgSHXjw8sOZW2ji4+e9dz5W6KJOkYGHL9mNM4kne+aha3PriOR9a5O4EkDVeG3AA+csU8poyq5U+//SvaOrrK3RxJ0lEw5AYwsqbA//mNM1m5eQ9f+Jm3FEjScGTIHcZlp0/i18+awmfvXsXqZpf7kqThZlAhFxFXRsTKiFgVER87zHlviYgUEYuGronl9RdvWkBtIcfHv/0rurpSuZsjSXoZjhhyEZEHbgbeACwAro2IBf2c1wB8CHhoqBtZThMbavnTq07noTXb+c/lG8rdHEnSyzCYntxiYFVKaXVKqQ24Dbi6n/P+D/B/gZYhbN9J4bfPn8GFc8bxV3esYMvuzP16kpRZgwm5aa0GUz0AABjTSURBVEDvLkxT6ViPiDgPmJFS+uHhLhQRN0TE8ohY3tzc/LIbWy4RwV//1lm0dnTxF0ufKndzJEmDdMwTTyIiB3wa+OMjnZtS+kJKaVFKaVFjY+OxvvQJNXtCPR++fC4/evJFfvzki+VujiRpEAYTchuBGb0eTy8d69YAnAncGxFrgQuBpVmafNLt/RfP4fQpo/jE955k14H2cjdHknQEgwm5ZcDciJgdEdXANcDS7idTSrtSShNSSrNSSrOAB4E3p5SWH5cWl1FVPsf/fctCtu5t5a/vWFHu5kiSjuCIIZdS6gBuBO4EVgDfSCk9FRE3RcSbj3cDTzZnTR/DDa89lduWbeBLD6wpd3MkSYdRGMxJKaU7gDv6HPvEAOcuOfZmndw+esU8Vjfv5aYfPM2kUbVctXBKuZskSeqHK54chXwu+Oy153LezLF8+D8f46HV28rdJElSPwy5o1Rbledf37mIGWNH8P6vLueZF3eXu0mSpD4MuWMwtr6ar7xnMbVVed7y/37B9x9/odxNkiT1Ysgdo+lj6/juBy9i/pRR/P7XH+UT33uS1o7OcjdLkoQhNySmjhnBbTdcyPsvns1Xf7mOt37+l6zasqfczZKkimfIDZGqfI7//esL+MI7Xsn67ft5wz/ez9/d+QwH2uzVSVK5GHJD7NfOmMxdf3wJbzp7Kjff8zy/9g/3cc/KLeVuliRVJEPuOJgwsoZPv/0cvv7+C6nO53j3l5bxubufIyX3o5OkE8mQO45edep47vjQxfzmudP4+588y//61hO0d3aVu1mSVDEGteKJjl5NIc+n3342M8aO4LN3r2LTrhZuvu48RtVWlbtpkpR59uROgIjgj35tHn/7lrP45fPbeN3f3ctN33+ap17YVe6mSVKm2ZM7gd5+/gxOnVjPF3+2hlsfXMstD6xh/uQGPnz5aVx55uRyN0+SMifKNRli0aJFafnyzO3GM2g79rXxgyde4NYH1/Hs5r38xjlT+eSbz2BMXXW5myZJw0pEPJJS6ncPU4cry2RsfTXveNUsfvgHF/OHl5/GD57YxOs/8zPuWrG53E2TpMww5MqsKp/jQ5fP5bsfvIjx9dW89yvL+ZPbH2dPizuPS9KxMuROEmdOG83SG1/DB5acyu2PNHHlP9zPL593Cx9JOhbW5E5Cj6zbwUe++Thrtu7jyjMmM2lUDXU1Beqr81y+YBLzJ48qdxMl6aRxuJqcIXeS2t/Wwd/duZKfPLWZfW0d7G/tpK2zi5pCjr9961lcfc60cjdRkk4KhlxGbNnTwo3//igPr93O/7hkDn9yxXzyuSh3sySprJxdmRETG2r52vsu4LoLZvIv963mvV9ZxqPrd9DZ5ZqYktQfbwYfZqoLOT71mws5fcoo/vL7T3HvymZG1RZ49akTuGDOOGaOq2PqmBFMHTOC0SNcOkxSZTPkhqnfvfAUrlo4hQdWbeXnz23l/uea+fFTLx50znkzx/DZa89l+ti6MrVSksrLmlxGpJRo3tPKxp0HeGFnC2u27uVf7ltNPh/8w2+fw5J5E8vdREk6Lg5Xk7MnlxERwcRRtUwcVcu5M4vHfv2sqfzPrz3Cu7+8jN9/3Sv40OWnOVFFUkVx4kmGzZ5Qz3c+cBFvOW86n717Fa//zH18c/kG97STVDEMuYwbUZ3n7992Nv/8u+dRW8jz0dufYMnf3cuXHljDrv0uHSYp26zJVZCUEvc+28zNd69i+bodVOdzXHb6RH7z3GksmTeR6oL/55E0/FiTE1Cs271u3kReN28iv2raxbcfbWLpYy/woydfZExdFVctnMLVZ0/l/FnjyFm7k5QB9uQqXHtnF/c/18z3HnuBnzy1mQPtnUwZXctpkxrIBeRzQU0hz5VnTuYNZ06mkLe3J+nkYk9OA6rK57h0/iQunT+J/W0d/PTpzfzwiU1s3tNKV1eisyuxfV8bP/zVJqaOruVdr57FNefPZHSdN5pLOvnZk9MRdXUl7n5mC//28zX8cvU2cgEzxtXxisaRnDpxJPMnN3DuzLHMGl9HhMOckk4se3I6JrlccPmCSVy+YBJPbtzFT57ezPNb9rJqy17uf24rbaVbEsbUVXHOjDG89zWzuXhuY5lbLUmGnF6mM6eN5sxpo3sed3R2sap5L4+u38lj63fy81Vbece/Pcw7LjyFj181n7rqlz5irR2ddHalg45J0vHkvzY6JoV8jvmTRzF/8iiuXTyTlvZO/vbHK7nlgTXc/1wz//vXF7Bh+37uf66ZB1dvJ5G45vyZvP+1c5g2ZkS5my8p46zJ6bj45fPb+Mg3H2fjzgNAcfWV186dwN7WTr732EYArj5nGjPGjWBVaejzxd0t/PrCKdx46SuYMvrgANzX2kF1IUeVszsl9eGmqSqLPS3tPLBqK2dMHc2McS/thPDCzgN88f7V3PbwBlo6Opkxto5XTBxJfU2BHz+5iSD4nQtm8qazp/Dwmh3cs3IL/71uBxMbavin3zmPV54ytoy/laSTjSGnk9L+tg5yEdRW5XuONe3Yz833rOKby5voKG0Ge/qUUVw8dwI/enITm3a28CdXzuN9r5njDeuSAENOw9D6bft5rGkni2eNY/LoWgB2HWjnf93+BD9+6kUumz+RP3vjAmZPqC9zSyWVmyGnzEgp8dVfruNTP1xBW2cX8yY1cOWZk3ntaRM40NZF894Wmve00tbRxZi6asbWVTO2vopRtVU01BYYWVNgZG2BmkL+yC8maVgw5JQ5m3Yd4Ee/epEfP/kiy9Zt5+V+jE9trOecGWM5Z+YYLpw9jrmTGo5PQyUdd4acMm3LnhYeW7+TMXXVTBhZTWNDDdWFHLv2t7N9fxs79rWzu6WdvS0d7G3tYNu+Np7auIvHNuxk2742AK5aOJk//rV5nNo4ssy/jaSXyxVPlGkTG2r5tTMmH3p8VJ6Jo2oH/LmUEk07DvCt/27iiz9bzZ1Pbebti6bz3tfM4dTGepcokzLAnpwEbN3byufuXsW/P7SO9s7E+PpqzjtlLItOGcuiWWM5c9po63jSScrhSmmQXth5gPuebWb52h08sm47a7ftB6C6kOOsaaM5fcoo9rS007y3leY9rexr7SSXg3wEuVywYMoo3nT2VJbMazQUpRPEkJOO0ta9rTyybgePrNvB8rXbeW7LXsb2qv3V1xQgQWdKtHV08dCa7Wzf10ZDbYHXnz6J6WNH0FCa2Tl1zAhedep4V22Rhpg1OekoTRhZwxVnTOaKfmp+/Wnv7OIXz29j6WMvcM/KLezY33bQzM/Ghhre+srpvH3RDGZPqKe1o5Pt+9rYdaCdmePqXLxaGmL25KTjqKsrsa+tgz0tHTy5cRffWN7EPSu30NmVqK/Os6+ts+fcfC44c+oozp81jgvmjOdVp45nZI2hJx2Jw5XSSWTz7ha+8+hGNu9uYXx9NWPrq2morWLli7tZtmYHjzXtpK2ji+p8jgvmjON18yby+gWTDlr/U9JLDDlpGGlp7+S/1+/g3pXN3LViM8837wPg/Flj+a3zpnPVwimMHlHF3tYONu08wI797SyYOspenyqWIScNY+u27eMHT2zi2//dxPPN+6gu5KjJ59jT2tFzTlU+OH/WOJbMa+TUxpE8uXE3j23YweNNu6jKB4tnj2fx7HFcMHsc4+urKeRyFPJBTSFHwYkwGuYMOSkDUko80bSL7z/+Ah1diSmja5k8upaG2gIPr9nBvSu38MyLewCIgLkTR3LOjDG0tHfx0JptbN7desg1q/M5LpnXyNXnTOWy+ZMYUe1tDxp+DDmpQryw8wAbtu9nwdRRNNRW9RxPKbF++34eWbeDva0dtHcmOjq72LSrhTt+tYkte1qpr85z/uxxTBhZ01MrbO/oYsf+dnbub2NvawczxtUxb1IDcyeNZN7kBmeD6qRgyEkaUGdX4qE12/j+4y/wRNMutu9rY9u+Nto6ugAYWVNgTF0VddV51m/fT0t78XhtVY63vnI677loNnNc81Nl5H1ykgaUzwWvPnUCrz51Qs+xlBL72zpLdbuXhjA7uxIbtu/n2c17+K8Vm/nG8ia+9uB6Lp0/kdfNn0h9dZ666jw1hTybd7ewbvt+1m/bz97WDt541hTedPbUgzbJlY43e3KSjtrWva187cF13PrLdT07OvRWlQ+mj60jpcTabfsZPaKKt75yOpfOn0i+tLN7ALMm1DPpMItpS4dzzMOVEXEl8I9AHvjXlNLf9Hn+94APAp3AXuCGlNLTh7umISdlR3tnFzv2tbG/rZP9bZ20dHTSOLKGqWNGkM8FKSUeWrOdWx9cx51PvkhH16H/7swaX8fi2eNYOH0MzXtaeX7LXp5v3su2fW2MratiTF014+qqOXfmGH77/BmMqas+5BopJXePqEDHFHIRkQeeBV4PNAHLgGt7h1hEjEop7S59/2bgAymlKw93XUNOqkzNe1p5bsuensedXYmVL+7hoTXbWbZ2Ozv3t5MLmDmujlMbRzJhZA27DhT3Bty6t5XVzfuorcrxlvOmc90Fp7BtXyv3P7eV+5/bynOb9zBzfB3zJzdw2qQGzpo+mgvnjHeCTMYda01uMbAqpbS6dLHbgKuBnpDrDriSeqA8Y6CSTnqNDTU0NtQcdOziuY287+I5dHUlNu1uYcLI6gF3cVixaTdfemAN33ykiX9/aD1QHBZddMo4rn/1LDbs2M+KTXv40ZMvklJxB4kLZo9jybyJTBldS0dXcWZpS3sX67bvY03zPtZs3UcEvP/iOfzmudO8dzBDBtOTeytwZUrpfaXH7wAuSCnd2Oe8DwJ/BFQDl6aUnuvnWjcANwDMnDnzlevWrRuSX0JS5dm2t5U7nnyR6WNHcMHscYf01g60FVeOueeZLdyzckvPyjG9VedznDK+jtkT6tm48wBPvbCbORPq+dDlczl3xlhWNe9h1Za9rN22n4aa4k4S08aMYHZjvbvIn0SOdbhyUCHX6/zfAa5IKb3rcNd1uFLSibRx5wH2tnRQyAeFXFBdyDGxobZnAkxKiZ88vZlP/+RZVm7ec9DPjq2rYl9rJ22dXT3Hzp81lve+Zg6vXzCJfC7Y29rBvSu3cO/KZsaPrOaS0xpZdMo4qgv2Co+3Yw25VwGfTCldUXr8cYCU0l8PcH4O2JFSGn246xpykk5GXV2Jn67YzI59bcydNJJXNDYwuq6Krq7Etn1tvLDzAMvWbufLv1hL044DzBxX7An+8vlttHV2Maauin2lG+7rq/O86tQJvPa0CVz0ignMmVDvxJjj4FhDrkBx4sllwEaKE09+J6X0VK9z5nYPT0bEm4C/GOgFuxlykoazjs4ufvr0Zm55YA3b9rZx6fyJXHHmZM6bOZYD7Z388vlt3PfsFu57tpkN2w8AMHV0LQumjqa9s4uW9k5aOrqY2FDDBbPHsXj2OE6fMoqVLxbvQbz7mS2sad7H1edO9Yb7IxiKWwiuAv6B4i0Et6SUPhURNwHLU0pLI+IfgcuBdmAHcGPvEOyPISepUqzbto+fr9rKz5/b2jM7tKYqT00hx/rt+1m3bT9QvDG/sysRAefOGMO0sXXc+eSLtHV2cen8iVx2+kQ6u4q70Ld1djFvUgOvPnXCYdcc7exKrNm6jwkjq/u97SILXNZLkk5im3e38PCa7fxq4y5Om9TA6+Y1Mn5kcQZq857iDfdfe7D/G+5rCjlefep4XjO3kZpCjtaOLto6umje08qTG3fx5Au72N/WSW1VjmvOn8n7Lp7N9LFHtzdhe2fx2vUn2bZOhpwkDXNtHV1s3dtKdSFHdSFHPoJH1+/krmc2c9eKLazfvv+g82urciyYMoqzpo9hwZRRLFu7ne88uhGAN541hSljRnCgrZP9bR20tHfR2ZWKXynR3tlFa3sXLR2dtLR3saelnV3723u2d3rDmZO58dJXcMbUg6dedHR2kYsglzuxdUdDTpIyLKVE857iVko1hXxxz8FC7pCweWHnAf71/jXctmw9bR1djCitNTqiKk8+F+RzQS6CqnyO2qoctaUh1VG1VYyuq2LMiGr2tXXw9YfWs6e1g9cvmMQVZ0xmxabdPLp+B0++sJuafI5zZo7hvJljOWfGGAr5YH9bJwfaOunsSkxoqGHSqBomNdQypq5qSCbiGHKSpB7HuvzZrgPtfPmBtfzbz1ezu6WDmkKOhdNGc/aMMbS0d/LIuh08u3kP/azedpD5kxv48Ydfe9Tt6OYuBJKkHsfaexo9oooPXT6X9148m6Yd+zm1cSRVfVaJ2dvawdMvFBfDqiv1GHMRbN3byubdrWze3XJCdqQw5CRJR2VkTYH5k0cN+Nzi2eMOOT5rQv3xbtZBvBVfkpRZhpwkKbMMOUlSZhlykqTMMuQkSZllyEmSMsuQkyRlliEnScosQ06SlFmGnCQpsww5SVJmGXKSpMwy5CRJmWXISZIyy5CTJGWWISdJyixDTpKUWYacJCmzDDlJUmYZcpKkzDLkJEmZFSml8rxwRDOwbgguNQHYOgTXqQS+V4Pj+zQ4vk+D53s1OEf7Pp2SUmrs74myhdxQiYjlKaVF5W7HcOB7NTi+T4Pj+zR4vleDczzeJ4crJUmZZchJkjIrCyH3hXI3YBjxvRoc36fB8X0aPN+rwRny92nY1+QkSRpIFnpykiT1y5CTJGXWsA65iLgyIlZGxKqI+Fi523OyiIgZEXFPRDwdEU9FxIdKx8dFxE8j4rnSn2PL3daTQUTkI+LRiPhB6fHsiHio9Ln6z4ioLncbTwYRMSYibo+IZyJiRUS8ys/UoSLiD0t/756MiK9HRK2fKYiIWyJiS0Q82etYv5+fKPps6f16IiLOO9rXHbYhFxF54GbgDcAC4NqIWFDeVp00OoA/TiktAC4EPlh6bz4G3JVSmgvcVXos+BCwotfj/wt8JqX0CmAH8N6ytOrk84/Aj1NK84GzKb5nfqZ6iYhpwB8Ai1JKZwJ54Br8TAF8Gbiyz7GBPj9vAOaWvm4APn+0LzpsQw5YDKxKKa1OKbUBtwFXl7lNJ4WU0qaU0n+Xvt9D8R+jaRTfn6+UTvsK8BvlaeHJIyKmA78O/GvpcQCXAreXTvF9AiJiNPBa4N8AUkptKaWd+JnqTwEYEREFoA7YhJ8pUko/A7b3OTzQ5+dq4Kup6EFgTERMOZrXHc4hNw3Y0OtxU+mYeomIWcC5wEPApJTSptJTLwKTytSsk8k/AH8CdJUejwd2ppQ6So/9XBXNBpqBL5WGdv81IurxM3WQlNJG4O+B9RTDbRfwCH6mBjLQ52fI/n0fziGnI4iIkcC3gA+nlHb3fi4V7x2p6PtHIuKNwJaU0iPlbsswUADOAz6fUjoX2EefoUk/U1CqKV1N8T8FU4F6Dh2iUz+O1+dnOIfcRmBGr8fTS8cEREQVxYD795TSt0uHN3d3+Ut/bilX+04SFwFvjoi1FIe7L6VYdxpTGmoCP1fdmoCmlNJDpce3Uww9P1MHuxxYk1JqTim1A9+m+DnzM9W/gT4/Q/bv+3AOuWXA3NKspWqKxd2lZW7TSaFUV/o3YEVK6dO9nloKvKv0/buA753otp1MUkofTylNTynNovj5uTuldB1wD/DW0mkV/z4BpJReBDZExLzSocuAp/Ez1dd64MKIqCv9Pex+n/xM9W+gz89S4J2lWZYXArt6DWu+LMN6xZOIuIpiTSUP3JJS+lSZm3RSiIjXAPcDv+KlWtOfUqzLfQOYSXGbo7enlPoWgitSRCwBPpJSemNEzKHYsxsHPAr8bkqptZztOxlExDkUJ+hUA6uBd1P8j7KfqV4i4i+B36Y4y/lR4H0U60kV/ZmKiK8DSyhup7MZ+Avgu/Tz+Sn9B+FzFId69wPvTiktP6rXHc4hJ0nS4Qzn4UpJkg7LkJMkZZYhJ0nKLENOkpRZhpwkKbMMOWmYi4gl3TsoSDqYISdJyixDTjpBIuJ3I+LhiHgsIv6ltI/d3oj4TGn/sbsiorF07jkR8WBpL63v9Npn6xUR8V8R8XhE/HdEnFq6/Mhee739e+lmWqniGXLSCRARp1NcBeOilNI5QCdwHcUFfJenlM4A7qO4CgTAV4H/lVI6i+LKNd3H/x24OaV0NvBqiivdQ3GniQ9T3FtxDsX1EqWKVzjyKZKGwGXAK4FlpU7WCIqL0XYB/1k652vAt0t7t41JKd1XOv4V4JsR0QBMSyl9ByCl1AJQut7DKaWm0uPHgFnAz4//ryWd3Aw56cQI4CsppY8fdDDiz/ucd7Tr7PVeB7ET/25LgMOV0olyF/DWiJgIEBHjIuIUin8Hu1en/x3g5ymlXcCOiLi4dPwdwH2lXd6bIuI3SteoiYi6E/pbSMOM/9uTToCU0tMR8WfATyIiB7QDH6S4+eji0nNbKNbtoLjtyD+XQqx7xX8oBt6/RMRNpWu87QT+GtKw4y4EUhlFxN6U0shyt0PKKocrJUmZZU9OkpRZ9uQkSZllyEmSMsuQkyRlliEnScosQ06SlFn/P5Z+0sjXGqonAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "mean loss\n",
            "\tmean loss        \t (min:    0.287, max:    1.005, cur:    0.287)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGhebLuY2Z7y"
      },
      "source": [
        "### [Generating](#scrollTo=RN2bUYhoZJX2&line=1&uniqifier=1) new quotes by character GRU model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYVkUvir2dHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03ef2a0-05c4-4454-c5da-ca76271d10c9"
      },
      "source": [
        "for _ in range(10):\n",
        "    print(generate_sample(best_char_gru_model, tokens, token_to_id, max_length=150, seed_phrase=' Neural networks', temperature=0.5, device='cpu'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Neural networks are about individuals. There is no such thing as a decent gift of being an individual to sound about what is concerned.              \n",
            " Neural networks are as great at the time they were able to defend themselves of themselves.                                                          \n",
            " Neural networks are the more our disposal that you can do and say.                                                                                   \n",
            " Neural networks will never be explained for your computer gardeners.                                                                                 \n",
            " Neural networks are always good at once, then what you can do in your life, and you are not something that you can get away from.                    \n",
            " Neural networks are as bad as they are as integrity as some level. They don't act out to be the shock.                                               \n",
            " Neural networks are not too late and I will not be affinitely ticket to the people I know.                                                           \n",
            " Neural networks are a company that does not always do with the products.                                                                             \n",
            " Neural networks are worth having a problem for doing their own parts.                                                                                \n",
            " Neural networks are the most daring temperal theaters.                                                                                               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDjhnRt_HC-s"
      },
      "source": [
        "### Could save or load model: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CptBPDz8tWxd"
      },
      "source": [
        "# model_savepath = \"/tmp/char_gru_model_\" + best_char_gru_loss + \".pth\"\r\n",
        "# torch.save(best_char_gru_model.state_dict(), model_savepath)\r\n",
        "# files.download(model_savepath)\r\n",
        "\r\n",
        "# model_name = \"\"\r\n",
        "# model_loadpath = f\"/content/gdrive/My Drive/ML/models/{model_name}\" \r\n",
        "# loaded_model = RNN_model(\"GRU\", num_tokens, emb_size=EMB_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS)\r\n",
        "# loaded_model.load_state_dict(torch.load(model_loadpath))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOZnmPYaDy0M"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xr9j-XS6PHU"
      },
      "source": [
        "## [BPE GRU model](#scrollTo=2QZ4jvNtRoop&line=1&uniqifier=1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr0qIndFtJK5"
      },
      "source": [
        "EMB_SIZE = 128\r\n",
        "HIDDEN_SIZE = 256\r\n",
        "NUM_LAYERS = 3\r\n",
        "\r\n",
        "bpe_gru_model = RNN_model(\"GRU\", num_tokens_bpe, emb_size=EMB_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfiOHO3U6Yqi"
      },
      "source": [
        "### [Training](#scrollTo=0-aBS-yD5Crc&line=1&uniqifier=1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUWZTogx2IeR"
      },
      "source": [
        "# scheduler = lambda optim: \\\n",
        "#     torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=5, factor=0.5, verbose=True)\n",
        "\n",
        "scheduler = lambda optim: \\\n",
        "    torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.95)\n",
        "\n",
        "best_bpe_gru_loss, best_bpe_gru_model = train_eval_loop(model=bpe_gru_model,\n",
        "                                                        dataset=quotes_bpe,\n",
        "                                                        lr=1e-3,\n",
        "                                                        epoch_n=150,\n",
        "                                                        batch_size=batch_size, \n",
        "                                                        early_stopping_patience=10,\n",
        "                                                        l2_reg_alpha=0,\n",
        "                                                        lr_scheduler_ctor=scheduler,\n",
        "                                                        draw_loss=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbG-fiLJ6grh"
      },
      "source": [
        "### [Generating](#scrollTo=AV8Bhw02i4sc&line=1&uniqifier=1) new quotes by BPE GRU model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHWggtvk6kiQ"
      },
      "source": [
        "for _ in range(10):\n",
        "    print(generate_sample_bpe(best_bpe_gru_model, tokenizer, max_length=150, seed_phrase=' ', temperature=1.0, device='cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}